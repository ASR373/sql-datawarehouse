
# ğŸ“¦ SQL Data Warehouse Project

## ğŸ“‘ Table of Contents

1. [Overview](#overview)  
2. [Repository Structure](#repository-structure)  
3. [High-Level Architecture](#high-level-architecture)  
   - [Bronze Layer (Raw Zone)](#bronze-layer-raw-zone)  
   - [Silver Layer (Cleansed Zone)](#silver-layer-cleansed-zone)  
   - [Gold Layer (Business Zone)](#gold-layer-business-zone)  
4. [Data Flow (Lineage)](#data-flow-lineage)  
5. [Data Integration (Table Relationships)](#data-integration-table-relationships)  
6. [Setup Instructions](#setup-instructions)  
   - [Requirements](#requirements)  
   - [Setup Steps](#setup-steps)  
7. [Project Learnings](#project-learnings)  
8. [Contributing](#contributing)  
9. [License](#license)  
10. [Contact](#contact)  

---

## ğŸ§  Overview

This project implements a full-featured **SQL-based Data Warehouse** using **PostgreSQL**, based on the **Medallion Architecture** (Bronze, Silver, and Gold layers). It demonstrates end-to-end ETL processes involving ERP and CRM data sources, with focus on:

- Schema standardization  
- Data transformation logic  
- Layered warehousing  
- Business-readiness of data  

---

## ğŸ—‚ï¸ Repository Structure

```
sql-datawarehouse/
â”œâ”€â”€ datasets/                   
â”‚   â”œâ”€â”€ source_erp/             # ERP raw CSV files
â”‚   â”‚   â”œâ”€â”€ customers.csv       
â”‚   â”‚   â””â”€â”€ products.csv        
â”‚   â””â”€â”€ source_crm/             # CRM raw CSV files
â”‚       â”œâ”€â”€ sales_details.csv  
â”‚       â””â”€â”€ customer_info.csv  
â”œâ”€â”€ docs/                       
â”‚   â”œâ”€â”€ high_level_architechture.png  
â”‚   â”œâ”€â”€ data_flow.png           
â”‚   â”œâ”€â”€ data_integration.png    
â”‚   â””â”€â”€ erd.png                 
â”œâ”€â”€ scripts/                    
â”‚   â”œâ”€â”€ 01_create_schemas.sql   # Schema creation scripts
â”‚   â”œâ”€â”€ 02_create_tables.sql    # Table definitions for Bronze/Silver/Gold
â”‚   â”œâ”€â”€ 03_load_data.py         # Python load script using psycopg2
â”‚   â”œâ”€â”€ 04_transformations.sql  # Silver & Gold transformation logic
â”‚   â””â”€â”€ 05_data_quality_checks.sql  # Data validation SQL
â”œâ”€â”€ tests/                      
â”‚   â”œâ”€â”€ quality_check_silver.sql
â”‚   â””â”€â”€ quality_check_gold.sql  
â”œâ”€â”€ run_setup.sh                # Automates the full pipeline
â””â”€â”€ README.md                   # Project documentation (this file)
```

> **Note:** Each directory is organized by pipeline stage:
> - `datasets/`: Source files  
> - `docs/`: Diagrams and ERDs  
> - `scripts/`: ETL logic  
> - `tests/`: Validation queries  

---

## ğŸ§± High-Level Architecture

The warehouse is built on the **Medallion Architecture**, which organizes data into three progressive layers:

![High-Level Architecture](docs/high_level_architechture.png)

### ğŸ”¸ Bronze Layer (Raw Zone)
- **Purpose**: Store raw ingested data without transformation.  
- **Source**: Direct load from CSV files (ERP, CRM).  
- **Objects**: Tables (`erp_cust_a12`, `crm_sales_details`, etc.)  
- **Load Strategy**: Batch/full load  
- **Why Needed**: Preserves data lineage, reproducibility.

### âšª Silver Layer (Cleansed Zone)
- **Purpose**: Normalize, clean, standardize data.  
- **Transformations**:
  - Data type casting  
  - Missing value treatment  
  - Joins across ERP & CRM  
- **Objects**: Refined tables (`erp_prd_info`, `crm_prdr_info`, etc.)  
- **Why Needed**: Business-safe layer for analytics and dashboards.

### ğŸŸ¡ Gold Layer (Business Zone)
- **Purpose**: Serve ready-to-query insights.  
- **Objects**: Aggregated views like `fact_sales`, `dim_products`, `dim_customers`.  
- **Business Logic**:
  - Calculated KPIs  
  - Summary views  
- **Why Needed**: Enables seamless BI integration.

---

## ğŸ”„ Data Flow (Lineage)

This diagram outlines the **data lineage**, showing how raw data evolves through each layer:

![Data Flow](docs/data_flow.png)

- **Bronze Layer**: Stores untouched raw tables from CRM & ERP.  
- **Silver Layer**: Cleans data, resolves duplicates, builds consistent structure.  
- **Gold Layer**: Aggregates and exposes dimensional and fact tables for analysis.

ğŸ“Œ For example:
- `crm_sales_details` â†’ `crm_sudit_detils` â†’ `fact_sales`  
- `erp_cust_a12` + `crm_cust_info` â†’ `dim_customers`

**Why this matters**:
- Clear traceability from source to insights  
- Ensures auditability  
- Allows isolating errors to a layer  

---

## ğŸ”— Data Integration (Table Relationships)

![Data Integration](docs/data_integration.png)

This diagram depicts how data from different systems is **integrated**:

- **CRM Tables** (e.g., `crm_prd_info`, `crm_sales_details`) hold transactional and product data.  
- **ERP Tables** (e.g., `erp_cust_a12`, `erp_px_cat_g1v2`) provide supplementary metadata.

ğŸ”— **Joins** are defined via shared keys like `cid` and `prd_key` to unify these sources.

ğŸ“Œ Example:
- Customer info is unified by combining `crm_cust_info` and `erp_cust_a12`.  
- Product info is built by linking `crm_prd_info` with `erp_px_cat_g1v2`.

**Why this matters**:
- Business entities (customer/product) often span systems.  
- Integration provides a 360-degree view of operations.

---

## âš™ï¸ Setup Instructions

### ğŸ”§ Requirements

- PostgreSQL 14+  
- Python 3.9+  
- Required packages:

```bash
pip install psycopg2 pandas
```

### ğŸ›  Setup Steps

1. **Clone the Repository**

```bash
git clone https://github.com/ASR373/sql-datawarehouse.git
cd sql-datawarehouse
```

2. **Configure Connection**

Edit `scripts/03_load_data.py` with your PostgreSQL credentials.

3. **Run the Setup Pipeline**

```bash
bash run_setup.sh
```

This will:
- Create schemas: `bronze`, `silver`, `gold`  
- Create all necessary tables  
- Load raw data into the Bronze layer  
- Run transformation SQL for Silver & Gold layers  

---

## ğŸ’¡ Project Learnings

- Realistic simulation of a data warehouse for CRM + ERP  
- Production-quality layer separation (Bronze/Silver/Gold)  
- Automated setup and testing flow  
- Illustrated architecture and table lineage for documentation clarity  

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---
